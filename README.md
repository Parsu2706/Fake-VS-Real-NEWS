# Fake vs Real News Detection using Machine Learning

This project focuses on detecting whether a news article is fake or real using Natural Language Processing (NLP) and Machine Learning. It uses TF-IDF vectorization and a Random Forest Classifier to perform binary classification. The project also includes a user-friendly Streamlit web app for interacting with the model â€” allowing users to visualize the dataset, predict article authenticity, and evaluate model performance in real-time.

Note: Some large files (e.g., datasets and model files) are not included in this repository to comply with GitHubâ€™s file size limits.  
To access the dataset, visit the Kaggle source: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset

---

## Project Highlights

- Model Used: Random Forest Classifier  
- Accuracy Achieved: ~98% on holdout test set  
- Web App: Built using Streamlit with interactive UI  
- Visualizations: Label/subject distribution, word clouds, confusion matrix  
- Text Analysis: TF-IDF vectorization and NLTK-based preprocessing  
- Deployment-Ready: Modular and scalable structure for future enhancements

---

## Key Features

### 1. Dataset Overview

- Preview top 10 rows  
- View data types of each column  
- Check for missing/null values  
- Display sample headlines and preprocessed text  
- Display article publication date range

### 2. Visualization Dashboard

- Bar chart: Fake vs Real article count  
- Bar chart: News subject/category frequency  
- Word clouds for most frequent words (Real and Fake)

### 3. News Authenticity Prediction

- Select or input article content  
- Automatically preprocess and vectorize input  
- Predict whether the article is â€œFake Newsâ€ or â€œReal Newsâ€

### 4. Model Evaluation

- Dataset is split 80/20 for training/testing  
- Outputs include:  
  - Accuracy score  
  - Precision, Recall, and F1-Score  
  - Confusion Matrix and Classification Report (visualized with heatmap)

---

## Project Structure

Fake-VS-Real-NEWS/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw/raw.csv # Raw data (excluded from repo)
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ best_rf_model.pkl
â”‚ â””â”€â”€ tfidf_vectorizer.pkl
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_loader.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ train.py
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ fake_news.ipynb
â”‚
â”œâ”€â”€ app.py # Streamlit web application
â”œâ”€â”€ run_preprocessing.py # Run data preprocessing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

Core Concepts and Formulas
ğŸ”¹ TF-IDF Vectorization
TF-IDF (Term Frequency-Inverse Document Frequency) weighs a wordâ€™s importance across documents:

TF-IDF
(
ğ‘¡
,
ğ‘‘
)
=
TF
(
ğ‘¡
,
ğ‘‘
)
Ã—
log
â¡
(
ğ‘
ğ·
ğ¹
(
ğ‘¡
)
)
TF-IDF(t,d)=TF(t,d)Ã—log( 
DF(t)
N
â€‹
 )
TF(t, d): Frequency of term t in document d

DF(t): Number of documents containing term t

N: Total number of documents in corpus

This helps eliminate common but uninformative words, giving more importance to discriminative terms.

ğŸ”¹ Evaluation Metrics
Accuracy

Accuracy
=
ğ‘‡
ğ‘ƒ
+
ğ‘‡
ğ‘
ğ‘‡
ğ‘ƒ
+
ğ‘‡
ğ‘
+
ğ¹
ğ‘ƒ
+
ğ¹
ğ‘
Accuracy= 
TP+TN+FP+FN
TP+TN
â€‹
 
Precision

Precision
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘ƒ
Precision= 
TP+FP
TP
â€‹
 
Recall

Recall
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘
Recall= 
TP+FN
TP
â€‹
 
F1-Score

F1
=
2
Ã—
Precision
Ã—
Recall
Precision
+
Recall
F1=2Ã— 
Precision+Recall
PrecisionÃ—Recall
â€‹
